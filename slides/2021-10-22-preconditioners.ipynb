{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dba1684",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2021-10-22 Preconditioners\n",
    "\n",
    "## Last time\n",
    "\n",
    "* Limitations of stationary iterative methods\n",
    "* Preconditioning as a concept\n",
    "* Krylov methods (GMRES)\n",
    "\n",
    "## Today\n",
    "* Experiments with preconditioners and diagnostics in PETSc\n",
    "* Basic preconditioners\n",
    "* Incomplete factorization and fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf84b17a",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grad_descent (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "using LinearAlgebra\n",
    "using SparseArrays\n",
    "\n",
    "default(linewidth=4)\n",
    "\n",
    "function advdiff_matrix(n; kappa=1, wind=[0, 0])\n",
    "    \"Advection-diffusion with Dirichlet boundary conditions eliminated\"\n",
    "    h = 2 / (n + 1)\n",
    "    rows = Vector{Int64}()\n",
    "    cols = Vector{Int64}()\n",
    "    vals = Vector{Float64}()\n",
    "    idx((i, j),) = (i-1)*n + j\n",
    "    in_domain((i, j),) = 1 <= i <= n && 1 <= j <= n\n",
    "    stencil_advect = [-wind[1], -wind[2], 0, wind[1], wind[2]] / h\n",
    "    stencil_diffuse = [-1, -1, 4, -1, -1] * kappa / h^2\n",
    "    stencil = stencil_advect + stencil_diffuse\n",
    "    for i in 1:n\n",
    "        for j in 1:n\n",
    "            neighbors = [(i-1, j), (i, j-1), (i, j), (i+1, j), (i, j+1)]\n",
    "            mask = in_domain.(neighbors)\n",
    "            append!(rows, idx.(repeat([(i,j)], 5))[mask])\n",
    "            append!(cols, idx.(neighbors)[mask])\n",
    "            append!(vals, stencil[mask])\n",
    "        end\n",
    "    end\n",
    "    sparse(rows, cols, vals)\n",
    "end\n",
    "\n",
    "function my_spy(A)\n",
    "    cmax = norm(vec(A), Inf)\n",
    "    s = max(1, ceil(120 / size(A, 1)))\n",
    "    spy(A, marker=(:square, s), c=:diverging_rainbow_bgymr_45_85_c67_n256, clims=(-cmax, cmax))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07ae2a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Experiments in [PETSc](https://petsc.org)\n",
    "\n",
    "* PETSc = Portable Extensible Toolkit for Scientific computing\n",
    "* `./configure`, `make`\n",
    "  * Depends on BLAS and LAPACK (default system or package manager)\n",
    "    * or `./configure --download-f2cblaslapack --download-blis`\n",
    "  * Depends on MPI for parallelism (package manager)\n",
    "    * or `./configure --download-mpich` (or `--download-openmpi`)\n",
    "* `docker run -it --rm jedbrown/petsc`\n",
    "* Lots of examples (mostly C and Fortran, some Python)\n",
    "* Experimental bindings in Rust, Julia\n",
    "* We'll use `src/snes/tutorials/ex15.c`\n",
    "  * \"p-Bratu\": combines p-Laplacian with Bratu nonlinearity\n",
    "  $$ -\\nabla\\cdot\\big(\\kappa(\\nabla u) \\nabla u\\big) - \\lambda e^u = f $$\n",
    "  * Newton solver with Krylov on each iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144760c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple preconditioners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c22dd4",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Jacobi `-pc_type jacobi`\n",
    "\n",
    "$$ P_{\\text{Jacobi}}^{-1} = D^{-1} $$\n",
    "where $D$ is the diagonal of $A$.\n",
    "\n",
    "## Gauss-Seidel `-pc_type sor`\n",
    "\n",
    "$$ P_{GS}^{-1} = (L+D)^{-1} $$\n",
    "where $L$ is the (strictly) lower triangular part of $A$.  The upper triangular part may be used instead, or a symmetric form\n",
    "$$ P_{SGS}^{-1} = (L+U)^{-1} A \\Big( I - (L+D)^{-1} \\Big) . $$\n",
    "\n",
    "### Over-relaxation\n",
    "\n",
    "`-pc_sor_omega 1.` is default (Gauss-Seidel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7d362",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "## Run p-Laplacian example\n",
    "```console\n",
    "$ cd src/snes/tutorials\n",
    "$ make ex15\n",
    "$ ./ex15 -da_refine 2 -dm_view\n",
    "$ ./ex15 -ksp_monitor -pc_type jacobi\n",
    "$ ./ex15 -snes_view\n",
    "```\n",
    "\n",
    "## Experiments\n",
    "\n",
    "* How does iteration count vary under grid refinement?\n",
    "* How sensitive is it to parameters\n",
    "  * p-Laplacian `-p` $> 1$ and `-epsilon` $> 0$\n",
    "  * Bratu `-lambda` $< 6.8$\n",
    "* How sensitive to `-ksp_gmres_restart`?\n",
    "* `-ksp_monitor_true_residual`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359efcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Symmetric problems\n",
    "\n",
    "## Lanczos iteration: like GMRES for symmetric problems\n",
    "\n",
    "If $A$ is symmetric, then $H = Q^T A Q$ is also symmetric.  Since $H$ is Hessenberg, this means $H$ is tridiagonal.  Instead of storing $Q_n$, it is sufficient to store only the last two columns since the iteration satisfies a 3-term recurrence.  The analog of GMRES for the symmetric case is called MINRES and is also useful for solving symmetric indefinite problems.\n",
    "\n",
    "## Conjugate Gradients: changing the norm\n",
    "\n",
    "Instead of minimizing the $A^T A$ norm of the error, the Conjugate Gradient method minimizes the $A$ norm of the error.  For $A$ to induce a norm, it must be symmetric positive definite.  [Jeremy Shewchuck's guide to CG](http://www.cs.cmu.edu/%7Equake-papers/painless-conjugate-gradient.pdf) is an excellent resource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f57e0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Incomplete factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185b6d73",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "* Start factoring like in a sparse direct solver\n",
    "  * **ILU(0)** Discard fill outside the sparsity pattern of $A$\n",
    "  * **ILU($k$)**: only allow $k$ levels of fill\n",
    "  * **ILUT($\\epsilon$)**: only keep fill values larger than $\\epsilon$\n",
    "\n",
    "## Experiments\n",
    "* Try `-pc_factor_levels 2`\n",
    "* Impact on cost (check `-log_view`)\n",
    "* Impact on scalability (`-da_refine 6`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a5f1b4",
   "metadata": {
    "cell_style": "split"
   },
   "source": [
    "## Kershaw (1978) matrix\n",
    "\n",
    "Incomplete Cholesky can break down for SPD matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e389a97",
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Float64}:\n",
       " 0.17157287525380904\n",
       " 0.17157287525381085\n",
       " 5.828427124746186\n",
       " 5.82842712474619"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = [3 -2 0 2; -2 3 -2 0; 0 -2 3 -2; 2 0 -2 3]\n",
    "eigvals(K)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  },
  "rise": {
   "enable_chalkboard": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
